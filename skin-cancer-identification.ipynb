{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "_cell_guid": "9fab3fd5-7331-4cee-b40c-2280ec102f17",
    "_uuid": "ccb90f75-83db-44f8-a4d3-81a18129c635",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import numpy as np\n",
    "from tkinter import filedialog, messagebox\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "_cell_guid": "25645d39-0703-485e-bf64-8924262c144e",
    "_uuid": "f6fb7250-fba6-4666-afe4-6f57aee20ec6",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dir = r\"C:\\Users\\Johin\\Desktop\\Practice\\Melanoma Skin Cancer\\melanoma_cancer_dataset\\train\"\n",
    "test_dir = r\"C:\\Users\\Johin\\Desktop\\Practice\\Melanoma Skin Cancer\\melanoma_cancer_dataset\\test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "_cell_guid": "b85437c8-7d39-43d9-a573-d5d9291060dc",
    "_uuid": "c7e28804-6014-4bc5-a737-19fef4ec6d92",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale = 1./255,\n",
    "                               horizontal_flip = True,\n",
    "                               rotation_range = 40,\n",
    "                               shear_range=0.2,\n",
    "                               width_shift_range = 0.2,\n",
    "                               height_shift_range = 0.2,\n",
    "                               zoom_range = 0.2,\n",
    "                               fill_mode = 'nearest')\n",
    "test_gen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "_cell_guid": "009642dd-1f5f-4533-8472-eb31ff7cd491",
    "_uuid": "7b25e9de-ead3-44ff-a116-866016305c06",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9605 images belonging to 2 classes.\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train = train_gen.flow_from_directory(train_dir,\n",
    "                                      target_size = (150,150),\n",
    "                                      class_mode = 'binary',\n",
    "                                      batch_size = 100\n",
    "                                     )\n",
    "test = test_gen.flow_from_directory(test_dir,\n",
    "                                   target_size = (150,150),\n",
    "                                   batch_size = 100,\n",
    "                                   class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "_cell_guid": "6767bab8-6761-457d-8404-50c44494343a",
    "_uuid": "9bbc5fa2-2c2a-493f-85af-6ee39e2a92ce",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape= (150,150,3)),\n",
    "                         keras.layers.MaxPooling2D(2,2),\n",
    "                         keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
    "                         keras.layers.MaxPooling2D(2,2),\n",
    "                         keras.layers.Flatten(),\n",
    "                         keras.layers.Dense(128, activation = 'relu'),\n",
    "                         keras.layers.Dense(1, activation = 'sigmoid')])\n",
    "model.compile(optimizer = RMSprop(learning_rate = 0.001), loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "_cell_guid": "ba6d03a8-b6ba-4001-8854-c87a6ada26be",
    "_uuid": "14021b7b-b181-45ec-bf02-874b7a39e107",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "10/10 [==============================] - 40s 4s/step - loss: 4.2131 - accuracy: 0.5480\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 36s 4s/step - loss: 0.6680 - accuracy: 0.6070\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.6698 - accuracy: 0.6420\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 32s 3s/step - loss: 0.5938 - accuracy: 0.6700\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.5914 - accuracy: 0.6685\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 31s 3s/step - loss: 0.5717 - accuracy: 0.7180\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.5324 - accuracy: 0.7250\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.5585 - accuracy: 0.6950\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 30s 3s/step - loss: 0.5286 - accuracy: 0.7280\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.4780 - accuracy: 0.7680\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.5086 - accuracy: 0.7710\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 29s 3s/step - loss: 0.4918 - accuracy: 0.7560\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.4200 - accuracy: 0.8130\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.4825 - accuracy: 0.7940\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.4320 - accuracy: 0.8030\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3929 - accuracy: 0.8160\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.4385 - accuracy: 0.8040\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3904 - accuracy: 0.8260\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3939 - accuracy: 0.8230\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.4471 - accuracy: 0.7900\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3987 - accuracy: 0.8280\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 28s 3s/step - loss: 0.3704 - accuracy: 0.8340\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3995 - accuracy: 0.8300\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3895 - accuracy: 0.8150\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 25s 2s/step - loss: 0.4224 - accuracy: 0.8088\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.3867 - accuracy: 0.8300\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3683 - accuracy: 0.8400\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 26s 3s/step - loss: 0.3944 - accuracy: 0.8530\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 27s 3s/step - loss: 0.4021 - accuracy: 0.8130\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 964s 107s/step - loss: 0.3897 - accuracy: 0.8300\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3941 - accuracy: 0.8250\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3538 - accuracy: 0.8380\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 23s 2s/step - loss: 0.3704 - accuracy: 0.8330\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.3643 - accuracy: 0.8320\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.3797 - accuracy: 0.8360\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 22s 2s/step - loss: 0.3885 - accuracy: 0.8360\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.3915 - accuracy: 0.8360\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.4152 - accuracy: 0.8055\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.3165 - accuracy: 0.8570\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3951 - accuracy: 0.8199\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.3895 - accuracy: 0.8310\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.3331 - accuracy: 0.8620\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.3855 - accuracy: 0.8240\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.3148 - accuracy: 0.8590\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.4172 - accuracy: 0.8340\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.3394 - accuracy: 0.8570\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 16s 2s/step - loss: 0.3685 - accuracy: 0.8166\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 17s 2s/step - loss: 0.3312 - accuracy: 0.8670\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 21s 2s/step - loss: 0.3283 - accuracy: 0.8680\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 18s 2s/step - loss: 0.3798 - accuracy: 0.8100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b823441a80>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train,\n",
    "         steps_per_epoch = 10,\n",
    "         epochs = 50,\n",
    "         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_cell_guid": "739ae568-c989-4290-8024-885a2b8e2a03",
    "_uuid": "ebef03aa-d2fa-4c41-be28-255637d7f38a",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 12s 1s/step - loss: 0.2744 - accuracy: 0.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.27444493770599365, 0.8840000033378601]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"melanoma_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "617b23cb-8a38-4a20-b843-ca4a8acad077",
    "_uuid": "169b0af8-ab7d-411a-98ba-db3d21942b62",
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "melanoma_model = model\n",
    "\n",
    "root = tk.Tk()\n",
    "root.title(\"Skin Cancer Detector\")\n",
    "root.geometry(\"400x400\")\n",
    "\n",
    "image_label = tk.Label(root)\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "prediction_label = tk.Label(root, font=('Helvetica', 18))\n",
    "prediction_label.pack(pady=10)\n",
    "\n",
    "def open_file_dialog():\n",
    "    filenames = filedialog.askopenfilenames(initialdir=\"/\", title=\"Select an Image\",\n",
    "                                          filetypes=[(\"Image Files\", \"*.png *.jpg *.jpeg\")])\n",
    "    if filenames:\n",
    "        for filename in filenames:\n",
    "            image = Image.open(filename)\n",
    "            image = image.resize((150, 150))\n",
    "            image = np.array(image)\n",
    "            if image.shape != (150, 150, 3):\n",
    "                messagebox.showerror(\"Error\", \"The selected image is not of the correct size or shape (150x150x3).\")\n",
    "                return\n",
    "            image = image.reshape(1, 150, 150, 3)\n",
    "            result = melanoma_model.predict(image)\n",
    "            if result > 0.5:\n",
    "                messagebox.showinfo(\"Prediction\", \"The selected image is classified as melanoma.\")\n",
    "            else:\n",
    "                messagebox.showinfo(\"Prediction\", \"The selected image is classified as not melanoma.\")\n",
    "\n",
    "open_file_button = tk.Button(root, text=\"Open file\", command=open_file_dialog)\n",
    "open_file_button.pack(pady=10)\n",
    "\n",
    "root.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
